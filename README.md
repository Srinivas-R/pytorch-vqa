Download the dataset from here:
https://visualqa.org/vqa_v1_download.html

Set the paths in the config.py file.
To use 2D vs 1D attention, and BERT vs LSTM, uncomment the relevant line in the __init__ function of model.py.
To train the model, run "python train.py".
